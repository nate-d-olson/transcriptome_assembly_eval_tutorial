<style>
.reveal h1, .reveal h2, .reveal h3 {
  word-wrap: normal;
  -moz-hyphens: none;
}

</style>

```{r setup, warning=FALSE, message=FALSE, echo = FALSE}
library(knitr)
library(readr)
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(ggplot2)
```

```{r source_dir, warning=FALSE, message=FALSE, echo = FALSE}
results_read <- list(
      no_mods = "data/no_mods/Trinity_sequences.Trinity.fixed/",
      corrected = "data/corrected/Assembly4_Corrected.Trinity.fixed/",
      trimmed = "data/trimmed/Assembly2_Trimmed.Trinity.fixed/",
      trimmedcorrected = "data/trimmedcorrected/Assembly3_TrimmedCorrected.Trinity.fixed/"
)
```

Transcriptome Assembly and Evaluation Tutorial
========================================================
author: Nate Olson and Leann Biancani
date: 5/11/2016
autosize: true

Introduction
========================================================

__Transcriptomics__
- Complete set of RNA transcripts in a sample
- RNA-seq methods utilize short-read sequencing technologies

__*De novo* Transcriptome Assembly__
- Constructing a transcriptome from RNA-seq data
- Many different methods & parameters for each method 

__Assembly Evaluation__
- Reference vs. read based methods

Tutorial Overview
========================================================
__Dataset__
- Raw RNAseq reads from *C. elegans*
- Read Trimming: Trim Galore 4.0
- Error Correction: BayesHammer (SPAdes 3.5)

__Assembly__
- *De novo* Assembly: Trinity 2.0.6

__Evaluation__
- read & reference based: TransRate

      
Dataset
========================================================
Data used to generate assemblies

__No Modifications__
- Raw RNAseq reads from *C. elegans*
- garbage in, garbage out?

__Trimmed Reads__
- Read Trimming with Trim Galore 4.0

__Corrected Reads__
- Error Correction with BayesHammer (SPAdes 3.5)

__Trimmed & Corrected Reads__
- TrimGalore & BayesHammer

Assembly Methods
========================================================
- Assembly
      - de bruin graph-based assembly: Trinity
      - datasets...

Assembly Results
========================================================
```{r echo=FALSE, message=FALSE, warning=FALSE}
assembly_metrics_df <- list(no_mods = "data/no_mods/", 
                            corrected = "data/corrected/",
                            trimmed = "data/trimmed/", 
                            trimmedcorrected = "data/trimmedcorrected/") %>% 
      map(paste0, "assemblies.csv") %>%  
      map_df(read_csv, .id = "read_set") %>% 
      select(-assembly) %>% 
      gather("metric","value", -read_set) %>% 
      mutate(read_set = factor(read_set, levels = c("no_mods","corrected","trimmed","trimmedcorrected")))
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
assembly_metrics_df %>% 
      filter(metric %in% c("n_seqs", "smallest", "largest", 
                           "n50", "n_with_orf")) %>%
      spread(metric, value) %>% 
      select(read_set, n_seqs, smallest, largest, n50, n_with_orf) %>% 
      rename(Dataset = read_set, `# of Contigs`=n_seqs, `Shortest Contig (bp)`=smallest,
              `Longest Contig (bp)`=largest, `N50 (bp)`=n50, `# Contigs with ORF`=n_with_orf) %>% 
      kable(digits = 2,
            caption = "Trinity _C. elegans_ transcriptome assembly summary metrics.")
```
N50 - largest contig (bp) where > 50% of bases in contigs > this length.

Evaluation Method Transrate
========================================================

__Read based method:__ 
* Map read and calculate score
* Contig Score 
      1. Edit distance
      2. Coverage
      3. Chimera
      4. Complete

****
__Reference based method:__

* Align contigs to reference   
* Reciprical Best Hit  
* Evaluate reference coverage  



Evaluation - Assembly Score
========================================================
left: 60%
__Transrate Score Summary__
```{r echo=FALSE, message=FALSE, warning=FALSE}
assembly_metrics_df %>% 
      filter(metric %in% c("score", "optimal_score", "cutoff", "weighted")) %>%
      spread(metric, value) %>% select(read_set, score, optimal_score, cutoff, weighted) %>% 
      rename(Dataset=read_set, `Assembly Score`=score, `Optimized Score`=optimal_score, `Contig Score Threshold`=cutoff, `Weighted Score`=weighted) %>% 
      kable(digits = 3,
            caption = "Trinity _C. elegans_ transcriptome Transrate score summary.")
```



Evaluation - Assembly Score Optimization
========================================================
```{r, message=FALSE, warning=FALSE, echo=FALSE}
assembly_score_opt <- results_read %>% map(paste0,"assembly_score_optimisation.csv") %>% 
      map_df(read_csv, .id = "read_set") %>% 
      mutate(read_set = factor(read_set, levels = c("no_mods","corrected","trimmed","trimmedcorrected")))
```


```{r fig.cap = "Relationship between the cutoff for contig score and assembly score.", echo=FALSE, warning=FALSE, mesage=FALSE, fig.width = 12}
assembly_score_opt %>% 
      ggplot() + geom_path(aes(x = cutoff, y = assembly_score, color = read_set)) +
            theme_bw() +
            labs(x = "Contig Score Threshold", y = "Assembly Score", color = "Dataset")
```

Threshold for optimal assembly score varies by dataset.  


Evaluation - Contig Metrics
========================================================


```{r echo=FALSE, warning=FALSE, message=FALSE}
contig_stat <- results_read %>% map(paste0,"contigs.csv") %>% 
      map_df(read_csv, .id = "read_set")

contig_cutoff <- assembly_metrics_df %>% filter(metric == "cutoff") %>% 
      select(-metric) %>% rename(cutoff = value)
contig_stat <- contig_stat %>% left_join(contig_cutoff) %>% 
      mutate(contig_filt = cutoff < score)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Contig score distribution by dataset.", fig.width = 12}
contig_stat %>% 
      ggplot() + geom_density(aes(x = score, color = read_set, fill = read_set), 
                              alpha = 0.25) + theme_bw() +
            labs(x = "Contig Score", y = "Density", color = "Dataset", fill = "Dataset")
```

Trimming resulted in more contigs with scores > 0.25.

Evaluation - Reference
========================================================
```{r source_ref_dir, warning=FALSE, message=FALSE, echo = FALSE}
results_ref <- list(
      no_mods = "data/no_mods_ref/Trinity_sequences.Trinity.fixed/",
      corrected = "data/corrected_ref/Assembly4_Corrected.Trinity.fixed/",
      trimmed = "data/trimmed_ref/Assembly2_Trimmed.Trinity.fixed/",
      trimmedcorrected = "data/trimmedcorrected_ref/Assembly3_TrimmedCorrected.Trinity.fixed/"
)
```

```{r, message=FALSE, warning=FALSE, echo=FALSE}
ref_contig <- results_ref %>% map(paste0,"contigs.csv") %>% 
      map_df(read_csv, .id = "read_set")
crb_contig <- ref_contig %>% filter(has_crb == "true")
contig_crb_score <- crb_contig %>% left_join(contig_stat)
```


```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.cap = "Relationship between reference and read based quality assessment.", fig.width = 12}
ggplot(contig_crb_score) + 
      geom_density2d(aes(x = reference_coverage, y = score), color = "darkblue") +
      geom_smooth(aes(x = reference_coverage, y = score), color = "darkorange") +
      facet_grid(contig_filt~read_set) +
      theme_bw() + labs(x = "Reference Transcript Coverage", y = "Contig Score")
```

Contig score is unrealated to reference transcript coverage.  

Conclusions
=======================================================
- Read trimming has a greater impact on assembly size and number of contigs than error correction.  
- Read based assembly evaluation - potentially biased by the use of un-modified reads  
- No clear relationship between contig score and reference coverage